{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN to classify images in the CIFAR-10 Dataset\n",
    "\n",
    "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The 10 classes are:\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> airplane\n",
    "<li>  automobile\n",
    "<li> bird\n",
    "<li>  cat\n",
    "<li> deer\n",
    "<li> dog\n",
    "<li>  frog\n",
    "<li>  horse\n",
    "<li>  ship\n",
    "<li>  truck\n",
    "</ol>\n",
    "\n",
    "For details about CIFAR-10 see:\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "For a compilation of published performance results on CIFAR 10, see:\n",
    "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "---\n",
    "\n",
    "### Building Convolutional Neural Nets\n",
    "\n",
    "In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (25709, 48, 48, 3)\n",
      "Train labels shape:  (25709,)\n",
      "Validation data shape:  (3000, 48, 48, 3)\n",
      "Validation labels shape:  (3000,)\n",
      "Public test data shape:  (1000, 48, 48, 3)\n",
      "Public test labels shape:  (1000,)\n",
      "Private test data shape:  (1000, 48, 48, 3)\n",
      "Private test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data, load_3d_data\n",
    "\n",
    "def get_data(num_training=25709, num_validation=3000, num_pub_test=1000, num_pri_test=1000):\n",
    "    \"\"\"\n",
    "    Load the dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = load_3d_data()\n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_pub_test))\n",
    "    X_pub_test = X_pub_test[mask]\n",
    "    y_pub_test = y_pub_test[mask]\n",
    "    mask = list(range(num_pri_test))\n",
    "    X_pri_test = X_pri_test[mask]\n",
    "    y_pri_test = y_pri_test[mask]\n",
    "\n",
    "#     # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_pub_test -= mean_image\n",
    "    X_pri_test -= mean_image  \n",
    "    return X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "    #return X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_pub_test, y_pub_test\n",
    "   del X_pri_test, y_pri_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "#X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Public test data shape: ', X_pub_test.shape)\n",
    "print('Public test labels shape: ', y_pub_test.shape)\n",
    "print('Private test data shape: ', X_pri_test.shape)\n",
    "print('Private test labels shape: ', y_pri_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[999].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[999])\n",
    "plt.imshow(X_train[999]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_pub_test = keras.utils.to_categorical(y_pub_test, num_classes)\n",
    "y_pri_test = keras.utils.to_categorical(y_pri_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "# As before, let's make everything float and scale\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_pub_test = X_pub_test.astype('float32')\n",
    "X_pri_test = X_pri_test.astype('float32')\n",
    "print(X_train.shape[1:])\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_pub_test /= 255\n",
    "X_pri_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jstndlee\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 48, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 50, 50, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   1792        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 48, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 24, 24, 48)   3120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 24, 24, 48)   192         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 24, 48)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 24, 24, 48)   20784       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 24, 24, 48)   192         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 24, 48)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 24, 24, 128)  6272        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 24, 24, 128)  512         res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 24, 24, 128)  16512       bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 24, 24, 128)  512         res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 24, 128)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 24, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 24, 24, 48)   6192        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 24, 24, 48)   192         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 24, 24, 48)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 24, 24, 48)   20784       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 24, 24, 48)   192         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 24, 48)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 24, 24, 128)  6272        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 24, 24, 128)  512         res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 24, 128)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 24, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 24, 24, 48)   6192        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 24, 24, 48)   192         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 24, 24, 48)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 24, 24, 48)   20784       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 24, 24, 48)   192         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 24, 24, 48)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 24, 24, 128)  6272        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 24, 24, 128)  512         res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 24, 128)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 24, 24, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 24, 24, 96)   12384       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 24, 24, 96)   384         res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 24, 24, 96)   0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 24, 24, 96)   83040       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 24, 24, 96)   384         res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 24, 24, 96)   0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 24, 24, 256)  24832       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 24, 24, 256)  1024        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 24, 24, 256)  65792       bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 24, 24, 256)  1024        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 24, 24, 256)  0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 24, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 24, 24, 96)   24672       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 24, 24, 96)   384         res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 24, 24, 96)   0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 24, 24, 96)   83040       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 24, 24, 96)   384         res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 24, 24, 96)   0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 24, 24, 256)  24832       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 24, 24, 256)  1024        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 24, 24, 256)  0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 24, 24, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 24, 24, 96)   24672       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 24, 24, 96)   384         res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 24, 24, 96)   0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 24, 24, 96)   83040       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 24, 24, 96)   384         res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 24, 24, 96)   0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 24, 24, 256)  24832       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 24, 24, 256)  1024        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 24, 24, 256)  0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 24, 24, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 12, 12, 256)  0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 36864)        0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc7 (Dense)                     (None, 7)            258055      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 834,023\n",
      "Trainable params: 829,095\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "def identity_block(x, f, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    x_shortcut = x\n",
    "    x = Conv2D(filters = F1, kernel_size = (1,1), strides = (1,1), padding = 'valid',name = conv_name_base + '2a',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding = 'same',name = conv_name_base + '2b',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters = F3, kernel_size = (1,1), strides = (1,1), padding = 'valid',name = conv_name_base + '2c',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, f, filters, stage, block, s = 2):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    x_shortcut = x\n",
    "    \n",
    "    x = Conv2D(F1, (1,1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(F2, (f,f), strides = (1,1), padding = 'same', name = conv_name_base + '2b',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(F3, (1,1), strides = (1,1), name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2c')(x)\n",
    "    \n",
    "    x_shortcut = Conv2D(F3, (1,1), strides = (s,s), name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(x_shortcut)\n",
    "    \n",
    "    x = layers.Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "input_shape = (48, 48, 3)\n",
    "classes = 7\n",
    "\n",
    "# Define the input as a tensor with shape input_shape\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "# Zero-Padding\n",
    "X = ZeroPadding2D((1, 1))(X_input)\n",
    "\n",
    "# Stage 1\n",
    "X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv1',)(X)\n",
    "X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "X = Activation('relu')(X)\n",
    "X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "\n",
    "# Stage 2\n",
    "X = convolutional_block(X, f = 3, filters = [48, 48, 128], stage = 2, block='a', s = 1)\n",
    "X = identity_block(X, 3, [48, 48, 128], stage=2, block='b')\n",
    "X = identity_block(X, 3, [48, 48, 128], stage=2, block='c')\n",
    "\n",
    "# Stage 3\n",
    "#X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 1)\n",
    "#X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "#X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "#X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "# Stage 4\n",
    "#X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 1)\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "# Stage 5\n",
    "X = convolutional_block(X, f = 3, filters = [96, 96, 256], stage = 5, block='a', s = 1)\n",
    "X = identity_block(X, 3, [96, 96, 256], stage=5, block='b')\n",
    "X = identity_block(X, 3, [96, 96, 256], stage=5, block='c')\n",
    "\n",
    "# AVGPOOL\n",
    "X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
    "\n",
    "# output layer\n",
    "X = Flatten()(X)\n",
    "X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.000030\n",
      "WARNING:tensorflow:From C:\\Users\\jstndlee\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25709 samples, validate on 3000 samples\n",
      "Epoch 1/30\n",
      "25709/25709 [==============================] - 64s 2ms/step - loss: 2.0724 - acc: 0.2553 - val_loss: 1.8537 - val_acc: 0.3043\n",
      "Epoch 2/30\n",
      "25709/25709 [==============================] - 59s 2ms/step - loss: 1.7295 - acc: 0.3431 - val_loss: 1.7403 - val_acc: 0.3493\n",
      "Epoch 3/30\n",
      "25709/25709 [==============================] - 57s 2ms/step - loss: 1.5695 - acc: 0.4062 - val_loss: 1.6875 - val_acc: 0.3800\n",
      "Epoch 4/30\n",
      "25709/25709 [==============================] - 57s 2ms/step - loss: 1.4356 - acc: 0.4584 - val_loss: 1.6384 - val_acc: 0.3927\n",
      "Epoch 5/30\n",
      "25709/25709 [==============================] - 60s 2ms/step - loss: 1.3255 - acc: 0.5025 - val_loss: 1.6156 - val_acc: 0.4100\n",
      "Epoch 6/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 1.2442 - acc: 0.5415 - val_loss: 1.6006 - val_acc: 0.4183\n",
      "Epoch 7/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 1.1554 - acc: 0.5793 - val_loss: 1.5622 - val_acc: 0.4173\n",
      "Epoch 8/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 1.0810 - acc: 0.6113 - val_loss: 1.5608 - val_acc: 0.4377\n",
      "Epoch 9/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 1.0005 - acc: 0.6542 - val_loss: 1.5152 - val_acc: 0.4550\n",
      "Epoch 10/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 0.9498 - acc: 0.6750 - val_loss: 1.5016 - val_acc: 0.4550\n",
      "Epoch 11/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 0.8922 - acc: 0.7001 - val_loss: 1.5295 - val_acc: 0.4400\n",
      "Epoch 12/30\n",
      "25709/25709 [==============================] - 56s 2ms/step - loss: 0.8359 - acc: 0.7284 - val_loss: 1.4918 - val_acc: 0.4623\n",
      "Epoch 13/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 0.7733 - acc: 0.7608 - val_loss: 1.5140 - val_acc: 0.4657\n",
      "Epoch 14/30\n",
      "25709/25709 [==============================] - 56s 2ms/step - loss: 0.7310 - acc: 0.7795 - val_loss: 1.4877 - val_acc: 0.4727\n",
      "Epoch 15/30\n",
      "25709/25709 [==============================] - 56s 2ms/step - loss: 0.6781 - acc: 0.8030 - val_loss: 1.5227 - val_acc: 0.4563\n",
      "Epoch 16/30\n",
      "25709/25709 [==============================] - 56s 2ms/step - loss: 0.6439 - acc: 0.8172 - val_loss: 1.5317 - val_acc: 0.4667\n",
      "Epoch 17/30\n",
      "25709/25709 [==============================] - 56s 2ms/step - loss: 0.5971 - acc: 0.8394 - val_loss: 1.4844 - val_acc: 0.4883\n",
      "Epoch 18/30\n",
      "25709/25709 [==============================] - 58s 2ms/step - loss: 0.5605 - acc: 0.8557 - val_loss: 1.5010 - val_acc: 0.4827\n",
      "Epoch 19/30\n",
      "24576/25709 [===========================>..] - ETA: 2s - loss: 0.5200 - acc: 0.8736"
     ]
    }
   ],
   "source": [
    "rate = 3e-5\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=rate, decay=1e-6)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "print('Learning rate: %f' % rate)\n",
    "loss = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=30,\n",
    "              validation_data=(X_val, y_val),\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "score = model.evaluate(X_pri_test, y_pri_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learning rate:', rate)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('cross_entropy loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"acc\"],'r-x', label=\"Train Accuracy\")\n",
    "    ax.plot(history.history[\"val_acc\"],'b-x', label=\"Validation Accuracy\")\n",
    "    ax.legend()\n",
    "    ax.set_title('accuracy')\n",
    "    ax.grid(True)\n",
    "    \n",
    "\n",
    "plot_loss_accuracy(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "img_tensor = image.img_to_array(X_train[999])\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()\n",
    "\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers[:12]] # Extracts the outputs of the top 12 layers\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input\n",
    "img_tensor = np.expand_dims(X_train[0], axis=0)\n",
    "activations = activation_model.predict(img_tensor) # Returns a list of five Numpy arrays: one array per layer activation\n",
    "classes = classifier.predict_classes(img_tensor, batch_size=1)\n",
    "print(\"Predicted class is:\",classes)\n",
    "layer_names = []\n",
    "for layer in classifier.layers[:12]:\n",
    "    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
    "    \n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
    "    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, # Displays the grid\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
