{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN to classify images in the CIFAR-10 Dataset\n",
    "\n",
    "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The 10 classes are:\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> airplane\n",
    "<li>  automobile\n",
    "<li> bird\n",
    "<li>  cat\n",
    "<li> deer\n",
    "<li> dog\n",
    "<li>  frog\n",
    "<li>  horse\n",
    "<li>  ship\n",
    "<li>  truck\n",
    "</ol>\n",
    "\n",
    "For details about CIFAR-10 see:\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "For a compilation of published performance results on CIFAR 10, see:\n",
    "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "---\n",
    "\n",
    "### Building Convolutional Neural Nets\n",
    "\n",
    "In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (25709, 48, 48, 3)\n",
      "Train labels shape:  (25709,)\n",
      "Validation data shape:  (3000, 48, 48, 3)\n",
      "Validation labels shape:  (3000,)\n",
      "Public test data shape:  (1000, 48, 48, 3)\n",
      "Public test labels shape:  (1000,)\n",
      "Private test data shape:  (1000, 48, 48, 3)\n",
      "Private test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data, load_3d_data\n",
    "\n",
    "def get_data(num_training=25709, num_validation=3000, num_pub_test=1000, num_pri_test=1000):\n",
    "    \"\"\"\n",
    "    Load the dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = load_3d_data()\n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_pub_test))\n",
    "    X_pub_test = X_pub_test[mask]\n",
    "    y_pub_test = y_pub_test[mask]\n",
    "    mask = list(range(num_pri_test))\n",
    "    X_pri_test = X_pri_test[mask]\n",
    "    y_pri_test = y_pri_test[mask]\n",
    "\n",
    "#     # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_pub_test -= mean_image\n",
    "    X_pri_test -= mean_image  \n",
    "    return X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "    #return X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_pub_test, y_pub_test\n",
    "   del X_pri_test, y_pri_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "#X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Public test data shape: ', X_pub_test.shape)\n",
    "print('Public test labels shape: ', y_pub_test.shape)\n",
    "print('Private test data shape: ', X_pri_test.shape)\n",
    "print('Private test labels shape: ', y_pri_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[999].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[999])\n",
    "plt.imshow(X_train[999]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_pub_test = keras.utils.to_categorical(y_pub_test, num_classes)\n",
    "y_pri_test = keras.utils.to_categorical(y_pri_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "# As before, let's make everything float and scale\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_pub_test = X_pub_test.astype('float32')\n",
    "X_pri_test = X_pri_test.astype('float32')\n",
    "print(X_train.shape[1:])\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_pub_test /= 255\n",
    "X_pri_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jstndlee\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\jstndlee\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 50, 50, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "res2a_branch2a (Conv2D)      (None, 24, 24, 48)        3120      \n",
      "_________________________________________________________________\n",
      "bn2a_branch2a (BatchNormaliz (None, 24, 24, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 48)        0         \n",
      "_________________________________________________________________\n",
      "res2a_branch2b (Conv2D)      (None, 24, 24, 48)        20784     \n",
      "_________________________________________________________________\n",
      "bn2a_branch2b (BatchNormaliz (None, 24, 24, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 48)        0         \n",
      "_________________________________________________________________\n",
      "res2a_branch2c (Conv2D)      (None, 24, 24, 128)       6272      \n",
      "_________________________________________________________________\n",
      "bn2a_branch2c (BatchNormaliz (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "res2a_branch1 (Conv2D)       (None, 24, 24, 128)       16512     \n",
      "_________________________________________________________________\n",
      "bn2a_branch1 (BatchNormaliza (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "avg_pool (AveragePooling2D)  (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                921650    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 972,151\n",
      "Trainable params: 971,319\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import regularizers\n",
    "\n",
    "def identity_block(x, f, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    x_shortcut = x\n",
    "    x = Conv2D(filters = F1, kernel_size = (1,1), strides = (1,1), padding = 'valid',name = conv_name_base + '2a',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding = 'same',name = conv_name_base + '2b',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters = F3, kernel_size = (1,1), strides = (1,1), padding = 'valid',name = conv_name_base + '2c',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2c')(x)\n",
    "\n",
    "    #x = layers.Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x_shortcut\n",
    "\n",
    "def convolutional_block(x, f, filters, stage, block, s = 2):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    x_shortcut = x\n",
    "    \n",
    "    x = Conv2D(F1, (1,1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(F2, (f,f), strides = (1,1), padding = 'same', name = conv_name_base + '2b',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(F3, (1,1), strides = (1,1), name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = BatchNormalization(axis = 3, name = bn_name_base + '2c')(x)\n",
    "    \n",
    "    x_shortcut = Conv2D(F3, (1,1), strides = (s,s), name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(x_shortcut)\n",
    "    \n",
    "    #x = layers.Add()([x, x_shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x_shortcut\n",
    "    \n",
    "\n",
    "input_shape = (48, 48, 3)\n",
    "classes = 7\n",
    "\n",
    "# Define the input as a tensor with shape input_shape\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "# Zero-Padding\n",
    "X = ZeroPadding2D((1, 1))(X_input)\n",
    "\n",
    "# Stage 1\n",
    "X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv1',)(X)\n",
    "X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "X = Activation('relu')(X)\n",
    "X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "\n",
    "# Stage 2\n",
    "X = convolutional_block(X, f = 3, filters = [48, 48, 128], stage = 2, block='a', s = 1)\n",
    "X = identity_block(X, 3, [48, 48, 128], stage=2, block='b')\n",
    "X = identity_block(X, 3, [48, 48, 128], stage=2, block='c')\n",
    "\n",
    "# Stage 3\n",
    "#X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 1)\n",
    "#X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "#X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "#X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "# Stage 4\n",
    "#X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 1)\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "#X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "# Stage 5\n",
    "#X = convolutional_block(X, f = 3, filters = [96, 96, 256], stage = 5, block='a', s = 1)\n",
    "#X = identity_block(X, 3, [96, 96, 256], stage=5, block='b')\n",
    "#X = identity_block(X, 3, [96, 96, 256], stage=5, block='c')\n",
    "\n",
    "# AVGPOOL\n",
    "X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
    "\n",
    "# output layer\n",
    "X = Flatten()(X)\n",
    "\n",
    "#X = Dense(100, activation='relu')(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "#X = BatchNormalization()(X)\n",
    "X = Dense(50, activation='relu', kernel_regularizer = regularizers.l2(0.03))(X)\n",
    "X = Dropout(0.75)(X)\n",
    "\n",
    "X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.000010\n",
      "WARNING:tensorflow:From C:\\Users\\jstndlee\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25709 samples, validate on 3000 samples\n",
      "Epoch 1/200\n",
      "25709/25709 [==============================] - 16s 605us/step - loss: 5.2909 - acc: 0.1794 - val_loss: 4.8113 - val_acc: 0.2560\n",
      "Epoch 2/200\n",
      "25709/25709 [==============================] - 13s 499us/step - loss: 4.8715 - acc: 0.2237 - val_loss: 4.7115 - val_acc: 0.2903\n",
      "Epoch 3/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 4.7365 - acc: 0.2473 - val_loss: 4.6118 - val_acc: 0.3080\n",
      "Epoch 4/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 4.6348 - acc: 0.2559 - val_loss: 4.5015 - val_acc: 0.3323\n",
      "Epoch 5/200\n",
      "25709/25709 [==============================] - 13s 498us/step - loss: 4.5307 - acc: 0.2649 - val_loss: 4.3899 - val_acc: 0.3563\n",
      "Epoch 6/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 4.4209 - acc: 0.2769 - val_loss: 4.2774 - val_acc: 0.3657\n",
      "Epoch 7/200\n",
      "25709/25709 [==============================] - 13s 491us/step - loss: 4.3083 - acc: 0.2871 - val_loss: 4.1626 - val_acc: 0.3803\n",
      "Epoch 8/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 4.2013 - acc: 0.2972 - val_loss: 4.0505 - val_acc: 0.3890\n",
      "Epoch 9/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 4.0979 - acc: 0.3047 - val_loss: 3.9418 - val_acc: 0.3973\n",
      "Epoch 10/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 3.9963 - acc: 0.3116 - val_loss: 3.8437 - val_acc: 0.4007\n",
      "Epoch 11/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 3.8862 - acc: 0.3232 - val_loss: 3.7423 - val_acc: 0.3997\n",
      "Epoch 12/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 3.7955 - acc: 0.3297 - val_loss: 3.6421 - val_acc: 0.4100\n",
      "Epoch 13/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 3.6983 - acc: 0.3316 - val_loss: 3.5466 - val_acc: 0.4087\n",
      "Epoch 14/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 3.6083 - acc: 0.3405 - val_loss: 3.4630 - val_acc: 0.4210\n",
      "Epoch 15/200\n",
      "25709/25709 [==============================] - 13s 490us/step - loss: 3.5191 - acc: 0.3491 - val_loss: 3.3828 - val_acc: 0.4180\n",
      "Epoch 16/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 3.4361 - acc: 0.3541 - val_loss: 3.2968 - val_acc: 0.4250\n",
      "Epoch 17/200\n",
      "25709/25709 [==============================] - 13s 499us/step - loss: 3.3603 - acc: 0.3551 - val_loss: 3.2202 - val_acc: 0.4250\n",
      "Epoch 18/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 3.2839 - acc: 0.3611 - val_loss: 3.1475 - val_acc: 0.4313\n",
      "Epoch 19/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 3.2088 - acc: 0.3735 - val_loss: 3.0832 - val_acc: 0.4383\n",
      "Epoch 20/200\n",
      "25709/25709 [==============================] - 12s 480us/step - loss: 3.1527 - acc: 0.3729 - val_loss: 3.0193 - val_acc: 0.4410\n",
      "Epoch 21/200\n",
      "25709/25709 [==============================] - 12s 485us/step - loss: 3.0923 - acc: 0.3755 - val_loss: 2.9648 - val_acc: 0.4393\n",
      "Epoch 22/200\n",
      "25709/25709 [==============================] - 12s 475us/step - loss: 3.0290 - acc: 0.3833 - val_loss: 2.9082 - val_acc: 0.4493\n",
      "Epoch 23/200\n",
      "25709/25709 [==============================] - 12s 470us/step - loss: 2.9728 - acc: 0.3897 - val_loss: 2.8534 - val_acc: 0.4543\n",
      "Epoch 24/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 2.9172 - acc: 0.3920 - val_loss: 2.8075 - val_acc: 0.4583\n",
      "Epoch 25/200\n",
      "25709/25709 [==============================] - 13s 502us/step - loss: 2.8693 - acc: 0.3962 - val_loss: 2.7550 - val_acc: 0.4603\n",
      "Epoch 26/200\n",
      "25709/25709 [==============================] - 13s 509us/step - loss: 2.8197 - acc: 0.4007 - val_loss: 2.7122 - val_acc: 0.4587\n",
      "Epoch 27/200\n",
      "25709/25709 [==============================] - 13s 489us/step - loss: 2.7757 - acc: 0.4095 - val_loss: 2.6699 - val_acc: 0.4647\n",
      "Epoch 28/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 2.7286 - acc: 0.4113 - val_loss: 2.6282 - val_acc: 0.4700\n",
      "Epoch 29/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 2.6819 - acc: 0.4157 - val_loss: 2.5887 - val_acc: 0.4710\n",
      "Epoch 30/200\n",
      "25709/25709 [==============================] - 13s 501us/step - loss: 2.6465 - acc: 0.4127 - val_loss: 2.5552 - val_acc: 0.4757\n",
      "Epoch 31/200\n",
      "25709/25709 [==============================] - 13s 500us/step - loss: 2.6034 - acc: 0.4237 - val_loss: 2.5160 - val_acc: 0.4833\n",
      "Epoch 32/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 2.5672 - acc: 0.4251 - val_loss: 2.4823 - val_acc: 0.4803\n",
      "Epoch 33/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 2.5327 - acc: 0.4283 - val_loss: 2.4506 - val_acc: 0.4780\n",
      "Epoch 34/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 2.5010 - acc: 0.4297 - val_loss: 2.4183 - val_acc: 0.4820\n",
      "Epoch 35/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 2.4600 - acc: 0.4371 - val_loss: 2.3889 - val_acc: 0.4910\n",
      "Epoch 36/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 2.4294 - acc: 0.4403 - val_loss: 2.3552 - val_acc: 0.4870\n",
      "Epoch 37/200\n",
      "25709/25709 [==============================] - 12s 484us/step - loss: 2.3925 - acc: 0.4448 - val_loss: 2.3220 - val_acc: 0.4900\n",
      "Epoch 38/200\n",
      "25709/25709 [==============================] - 12s 479us/step - loss: 2.3709 - acc: 0.4497 - val_loss: 2.2985 - val_acc: 0.4887\n",
      "Epoch 39/200\n",
      "25709/25709 [==============================] - 12s 474us/step - loss: 2.3321 - acc: 0.4534 - val_loss: 2.2729 - val_acc: 0.4927\n",
      "Epoch 40/200\n",
      "25709/25709 [==============================] - 12s 457us/step - loss: 2.3113 - acc: 0.4560 - val_loss: 2.2449 - val_acc: 0.4997\n",
      "Epoch 41/200\n",
      "25709/25709 [==============================] - 12s 464us/step - loss: 2.2844 - acc: 0.4539 - val_loss: 2.2244 - val_acc: 0.4960\n",
      "Epoch 42/200\n",
      "25709/25709 [==============================] - 12s 456us/step - loss: 2.2544 - acc: 0.4591 - val_loss: 2.1998 - val_acc: 0.5003\n",
      "Epoch 43/200\n",
      "25709/25709 [==============================] - 12s 458us/step - loss: 2.2298 - acc: 0.4618 - val_loss: 2.1783 - val_acc: 0.5030\n",
      "Epoch 44/200\n",
      "25709/25709 [==============================] - 12s 479us/step - loss: 2.1996 - acc: 0.4657 - val_loss: 2.1520 - val_acc: 0.4983\n",
      "Epoch 45/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 2.1850 - acc: 0.4619 - val_loss: 2.1353 - val_acc: 0.5060\n",
      "Epoch 46/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 2.1541 - acc: 0.4684 - val_loss: 2.1146 - val_acc: 0.5033\n",
      "Epoch 47/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 2.1302 - acc: 0.4700 - val_loss: 2.0914 - val_acc: 0.5047\n",
      "Epoch 48/200\n",
      "25709/25709 [==============================] - 12s 483us/step - loss: 2.1028 - acc: 0.4763 - val_loss: 2.0723 - val_acc: 0.5100\n",
      "Epoch 49/200\n",
      "25709/25709 [==============================] - 13s 490us/step - loss: 2.0896 - acc: 0.4742 - val_loss: 2.0549 - val_acc: 0.5107\n",
      "Epoch 50/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 2.0643 - acc: 0.4820 - val_loss: 2.0323 - val_acc: 0.5070\n",
      "Epoch 51/200\n",
      "25709/25709 [==============================] - 12s 480us/step - loss: 2.0415 - acc: 0.4816 - val_loss: 2.0145 - val_acc: 0.5140\n",
      "Epoch 52/200\n",
      "25709/25709 [==============================] - 12s 482us/step - loss: 2.0233 - acc: 0.4840 - val_loss: 1.9999 - val_acc: 0.5170\n",
      "Epoch 53/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 2.0035 - acc: 0.4824 - val_loss: 1.9805 - val_acc: 0.5180\n",
      "Epoch 54/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 1.9823 - acc: 0.4891 - val_loss: 1.9629 - val_acc: 0.5200\n",
      "Epoch 55/200\n",
      "25709/25709 [==============================] - 13s 500us/step - loss: 1.9595 - acc: 0.4926 - val_loss: 1.9468 - val_acc: 0.5150\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25709/25709 [==============================] - 13s 497us/step - loss: 1.9459 - acc: 0.4925 - val_loss: 1.9330 - val_acc: 0.5133\n",
      "Epoch 57/200\n",
      "25709/25709 [==============================] - 13s 499us/step - loss: 1.9197 - acc: 0.4980 - val_loss: 1.9126 - val_acc: 0.5177\n",
      "Epoch 58/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 1.9124 - acc: 0.4954 - val_loss: 1.8984 - val_acc: 0.5197\n",
      "Epoch 59/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 1.8886 - acc: 0.5010 - val_loss: 1.8835 - val_acc: 0.5173\n",
      "Epoch 60/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 1.8808 - acc: 0.5001 - val_loss: 1.8694 - val_acc: 0.5167\n",
      "Epoch 61/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.8611 - acc: 0.5056 - val_loss: 1.8579 - val_acc: 0.5230\n",
      "Epoch 62/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.8415 - acc: 0.5098 - val_loss: 1.8478 - val_acc: 0.5230\n",
      "Epoch 63/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.8232 - acc: 0.5063 - val_loss: 1.8340 - val_acc: 0.5217\n",
      "Epoch 64/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 1.8144 - acc: 0.5097 - val_loss: 1.8196 - val_acc: 0.5220\n",
      "Epoch 65/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.7987 - acc: 0.5138 - val_loss: 1.8097 - val_acc: 0.5210\n",
      "Epoch 66/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.7922 - acc: 0.5094 - val_loss: 1.7931 - val_acc: 0.5230\n",
      "Epoch 67/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.7707 - acc: 0.5121 - val_loss: 1.7835 - val_acc: 0.5230\n",
      "Epoch 68/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.7587 - acc: 0.5182 - val_loss: 1.7729 - val_acc: 0.5220\n",
      "Epoch 69/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.7439 - acc: 0.5205 - val_loss: 1.7643 - val_acc: 0.5217\n",
      "Epoch 70/200\n",
      "25709/25709 [==============================] - 13s 501us/step - loss: 1.7293 - acc: 0.5234 - val_loss: 1.7527 - val_acc: 0.5293\n",
      "Epoch 71/200\n",
      "25709/25709 [==============================] - 13s 486us/step - loss: 1.7212 - acc: 0.5235 - val_loss: 1.7440 - val_acc: 0.5243\n",
      "Epoch 72/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.7050 - acc: 0.5257 - val_loss: 1.7318 - val_acc: 0.5227\n",
      "Epoch 73/200\n",
      "25709/25709 [==============================] - 13s 491us/step - loss: 1.6888 - acc: 0.5274 - val_loss: 1.7215 - val_acc: 0.5243\n",
      "Epoch 74/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 1.6810 - acc: 0.5264 - val_loss: 1.7116 - val_acc: 0.5253\n",
      "Epoch 75/200\n",
      "25709/25709 [==============================] - 13s 498us/step - loss: 1.6703 - acc: 0.5284 - val_loss: 1.6988 - val_acc: 0.5293\n",
      "Epoch 76/200\n",
      "25709/25709 [==============================] - 12s 484us/step - loss: 1.6540 - acc: 0.5302 - val_loss: 1.6895 - val_acc: 0.5267\n",
      "Epoch 77/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.6479 - acc: 0.5354 - val_loss: 1.6814 - val_acc: 0.5290\n",
      "Epoch 78/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.6337 - acc: 0.5350 - val_loss: 1.6771 - val_acc: 0.5297\n",
      "Epoch 79/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.6209 - acc: 0.5372 - val_loss: 1.6697 - val_acc: 0.5260\n",
      "Epoch 80/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.6113 - acc: 0.5389 - val_loss: 1.6609 - val_acc: 0.5270\n",
      "Epoch 81/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.5996 - acc: 0.5406 - val_loss: 1.6528 - val_acc: 0.5307\n",
      "Epoch 82/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.5893 - acc: 0.5430 - val_loss: 1.6448 - val_acc: 0.5330\n",
      "Epoch 83/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 1.5792 - acc: 0.5439 - val_loss: 1.6353 - val_acc: 0.5260\n",
      "Epoch 84/200\n",
      "25709/25709 [==============================] - 13s 499us/step - loss: 1.5728 - acc: 0.5453 - val_loss: 1.6312 - val_acc: 0.5283\n",
      "Epoch 85/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.5623 - acc: 0.5455 - val_loss: 1.6235 - val_acc: 0.5333\n",
      "Epoch 86/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 1.5557 - acc: 0.5467 - val_loss: 1.6155 - val_acc: 0.5303\n",
      "Epoch 87/200\n",
      "25709/25709 [==============================] - 13s 487us/step - loss: 1.5484 - acc: 0.5473 - val_loss: 1.6075 - val_acc: 0.5323\n",
      "Epoch 88/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.5424 - acc: 0.5483 - val_loss: 1.6012 - val_acc: 0.5323\n",
      "Epoch 89/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.5241 - acc: 0.5523 - val_loss: 1.5945 - val_acc: 0.5310\n",
      "Epoch 90/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.5192 - acc: 0.5520 - val_loss: 1.5891 - val_acc: 0.5300\n",
      "Epoch 91/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.5056 - acc: 0.5572 - val_loss: 1.5820 - val_acc: 0.5357\n",
      "Epoch 92/200\n",
      "25709/25709 [==============================] - 12s 485us/step - loss: 1.5012 - acc: 0.5558 - val_loss: 1.5749 - val_acc: 0.5330\n",
      "Epoch 93/200\n",
      "25709/25709 [==============================] - 12s 480us/step - loss: 1.4961 - acc: 0.5579 - val_loss: 1.5713 - val_acc: 0.5333\n",
      "Epoch 94/200\n",
      "25709/25709 [==============================] - 12s 478us/step - loss: 1.4833 - acc: 0.5607 - val_loss: 1.5645 - val_acc: 0.5327\n",
      "Epoch 95/200\n",
      "25709/25709 [==============================] - 13s 498us/step - loss: 1.4717 - acc: 0.5635 - val_loss: 1.5621 - val_acc: 0.5363\n",
      "Epoch 96/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.4677 - acc: 0.5594 - val_loss: 1.5519 - val_acc: 0.5340\n",
      "Epoch 97/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.4646 - acc: 0.5656 - val_loss: 1.5497 - val_acc: 0.5337\n",
      "Epoch 98/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 1.4537 - acc: 0.5663 - val_loss: 1.5444 - val_acc: 0.5330\n",
      "Epoch 99/200\n",
      "25709/25709 [==============================] - 13s 487us/step - loss: 1.4484 - acc: 0.5638 - val_loss: 1.5390 - val_acc: 0.5343\n",
      "Epoch 100/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.4416 - acc: 0.5660 - val_loss: 1.5354 - val_acc: 0.5370\n",
      "Epoch 101/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.4307 - acc: 0.5738 - val_loss: 1.5300 - val_acc: 0.5427\n",
      "Epoch 102/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 1.4217 - acc: 0.5716 - val_loss: 1.5254 - val_acc: 0.5360\n",
      "Epoch 103/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 1.4257 - acc: 0.5644 - val_loss: 1.5214 - val_acc: 0.5340\n",
      "Epoch 104/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.4177 - acc: 0.5685 - val_loss: 1.5156 - val_acc: 0.5380\n",
      "Epoch 105/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 1.4060 - acc: 0.5735 - val_loss: 1.5108 - val_acc: 0.5373\n",
      "Epoch 106/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.4026 - acc: 0.5751 - val_loss: 1.5078 - val_acc: 0.5407\n",
      "Epoch 107/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.3968 - acc: 0.5730 - val_loss: 1.5036 - val_acc: 0.5433\n",
      "Epoch 108/200\n",
      "25709/25709 [==============================] - 12s 481us/step - loss: 1.3912 - acc: 0.5753 - val_loss: 1.5015 - val_acc: 0.5403\n",
      "Epoch 109/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.3832 - acc: 0.5757 - val_loss: 1.4989 - val_acc: 0.5430\n",
      "Epoch 110/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.3781 - acc: 0.5802 - val_loss: 1.4964 - val_acc: 0.5417\n",
      "Epoch 111/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.3751 - acc: 0.5784 - val_loss: 1.4864 - val_acc: 0.5500\n",
      "Epoch 112/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.3645 - acc: 0.5856 - val_loss: 1.4866 - val_acc: 0.5440\n",
      "Epoch 113/200\n",
      "25709/25709 [==============================] - 12s 484us/step - loss: 1.3605 - acc: 0.5821 - val_loss: 1.4835 - val_acc: 0.5427\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.3592 - acc: 0.5803 - val_loss: 1.4744 - val_acc: 0.5453\n",
      "Epoch 115/200\n",
      "25709/25709 [==============================] - 13s 490us/step - loss: 1.3512 - acc: 0.5825 - val_loss: 1.4755 - val_acc: 0.5437\n",
      "Epoch 116/200\n",
      "25709/25709 [==============================] - 13s 486us/step - loss: 1.3445 - acc: 0.5843 - val_loss: 1.4708 - val_acc: 0.5393\n",
      "Epoch 117/200\n",
      "25709/25709 [==============================] - 13s 499us/step - loss: 1.3384 - acc: 0.5859 - val_loss: 1.4719 - val_acc: 0.5420\n",
      "Epoch 118/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.3377 - acc: 0.5831 - val_loss: 1.4656 - val_acc: 0.5417\n",
      "Epoch 119/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.3321 - acc: 0.5872 - val_loss: 1.4646 - val_acc: 0.5457\n",
      "Epoch 120/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.3219 - acc: 0.5894 - val_loss: 1.4617 - val_acc: 0.5457\n",
      "Epoch 121/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.3217 - acc: 0.5860 - val_loss: 1.4578 - val_acc: 0.5427\n",
      "Epoch 122/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.3115 - acc: 0.5940 - val_loss: 1.4575 - val_acc: 0.5477\n",
      "Epoch 123/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 1.3076 - acc: 0.5943 - val_loss: 1.4527 - val_acc: 0.5467\n",
      "Epoch 124/200\n",
      "25709/25709 [==============================] - 13s 488us/step - loss: 1.3056 - acc: 0.5936 - val_loss: 1.4489 - val_acc: 0.5457\n",
      "Epoch 125/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.3009 - acc: 0.5947 - val_loss: 1.4471 - val_acc: 0.5447\n",
      "Epoch 126/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 1.2907 - acc: 0.6024 - val_loss: 1.4410 - val_acc: 0.5437\n",
      "Epoch 127/200\n",
      "25709/25709 [==============================] - 13s 489us/step - loss: 1.2909 - acc: 0.5952 - val_loss: 1.4422 - val_acc: 0.5397\n",
      "Epoch 128/200\n",
      "25709/25709 [==============================] - 12s 480us/step - loss: 1.2818 - acc: 0.5993 - val_loss: 1.4380 - val_acc: 0.5473\n",
      "Epoch 129/200\n",
      "25709/25709 [==============================] - 13s 487us/step - loss: 1.2807 - acc: 0.6026 - val_loss: 1.4352 - val_acc: 0.5420\n",
      "Epoch 130/200\n",
      "25709/25709 [==============================] - 12s 485us/step - loss: 1.2737 - acc: 0.6045 - val_loss: 1.4358 - val_acc: 0.5397\n",
      "Epoch 131/200\n",
      "25709/25709 [==============================] - 13s 489us/step - loss: 1.2741 - acc: 0.6013 - val_loss: 1.4327 - val_acc: 0.5410\n",
      "Epoch 132/200\n",
      "25709/25709 [==============================] - 12s 486us/step - loss: 1.2665 - acc: 0.6033 - val_loss: 1.4336 - val_acc: 0.5430\n",
      "Epoch 133/200\n",
      "25709/25709 [==============================] - 12s 467us/step - loss: 1.2672 - acc: 0.5996 - val_loss: 1.4265 - val_acc: 0.5450\n",
      "Epoch 134/200\n",
      "25709/25709 [==============================] - 12s 458us/step - loss: 1.2591 - acc: 0.6050 - val_loss: 1.4277 - val_acc: 0.5467\n",
      "Epoch 135/200\n",
      "25709/25709 [==============================] - 12s 457us/step - loss: 1.2558 - acc: 0.6068 - val_loss: 1.4232 - val_acc: 0.5470\n",
      "Epoch 136/200\n",
      "25709/25709 [==============================] - 12s 456us/step - loss: 1.2549 - acc: 0.6080 - val_loss: 1.4216 - val_acc: 0.5503\n",
      "Epoch 137/200\n",
      "25709/25709 [==============================] - 12s 456us/step - loss: 1.2436 - acc: 0.6079 - val_loss: 1.4194 - val_acc: 0.5450\n",
      "Epoch 138/200\n",
      "25709/25709 [==============================] - 12s 456us/step - loss: 1.2413 - acc: 0.6087 - val_loss: 1.4186 - val_acc: 0.5423\n",
      "Epoch 139/200\n",
      "25709/25709 [==============================] - 12s 469us/step - loss: 1.2390 - acc: 0.6093 - val_loss: 1.4181 - val_acc: 0.5440\n",
      "Epoch 140/200\n",
      "25709/25709 [==============================] - 13s 489us/step - loss: 1.2389 - acc: 0.6094 - val_loss: 1.4172 - val_acc: 0.5453\n",
      "Epoch 141/200\n",
      "25709/25709 [==============================] - 12s 483us/step - loss: 1.2336 - acc: 0.6121 - val_loss: 1.4122 - val_acc: 0.5443\n",
      "Epoch 142/200\n",
      "25709/25709 [==============================] - 12s 483us/step - loss: 1.2263 - acc: 0.6154 - val_loss: 1.4103 - val_acc: 0.5457\n",
      "Epoch 143/200\n",
      "25709/25709 [==============================] - 12s 484us/step - loss: 1.2268 - acc: 0.6147 - val_loss: 1.4071 - val_acc: 0.5487\n",
      "Epoch 144/200\n",
      "25709/25709 [==============================] - 13s 487us/step - loss: 1.2207 - acc: 0.6196 - val_loss: 1.4075 - val_acc: 0.5453\n",
      "Epoch 145/200\n",
      "25709/25709 [==============================] - 12s 482us/step - loss: 1.2228 - acc: 0.6146 - val_loss: 1.4033 - val_acc: 0.5447\n",
      "Epoch 146/200\n",
      "25709/25709 [==============================] - 12s 482us/step - loss: 1.2141 - acc: 0.6136 - val_loss: 1.4069 - val_acc: 0.5467\n",
      "Epoch 147/200\n",
      "25709/25709 [==============================] - 12s 484us/step - loss: 1.2096 - acc: 0.6168 - val_loss: 1.4026 - val_acc: 0.5497\n",
      "Epoch 148/200\n",
      "25709/25709 [==============================] - 12s 484us/step - loss: 1.2045 - acc: 0.6236 - val_loss: 1.4029 - val_acc: 0.5487\n",
      "Epoch 149/200\n",
      "25709/25709 [==============================] - 12s 483us/step - loss: 1.1997 - acc: 0.6232 - val_loss: 1.3994 - val_acc: 0.5483\n",
      "Epoch 150/200\n",
      "25709/25709 [==============================] - 13s 487us/step - loss: 1.1949 - acc: 0.6246 - val_loss: 1.3998 - val_acc: 0.5450\n",
      "Epoch 151/200\n",
      "25709/25709 [==============================] - 13s 490us/step - loss: 1.1955 - acc: 0.6228 - val_loss: 1.4016 - val_acc: 0.5427\n",
      "Epoch 152/200\n",
      "25709/25709 [==============================] - 13s 498us/step - loss: 1.1983 - acc: 0.6239 - val_loss: 1.3950 - val_acc: 0.5463\n",
      "Epoch 153/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.1925 - acc: 0.6246 - val_loss: 1.3982 - val_acc: 0.5453\n",
      "Epoch 154/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.1897 - acc: 0.6218 - val_loss: 1.3946 - val_acc: 0.5423\n",
      "Epoch 155/200\n",
      "25709/25709 [==============================] - 13s 490us/step - loss: 1.1855 - acc: 0.6250 - val_loss: 1.3954 - val_acc: 0.5457\n",
      "Epoch 156/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 1.1827 - acc: 0.6242 - val_loss: 1.3913 - val_acc: 0.5470\n",
      "Epoch 157/200\n",
      "25709/25709 [==============================] - 13s 489us/step - loss: 1.1817 - acc: 0.6265 - val_loss: 1.3929 - val_acc: 0.5447\n",
      "Epoch 158/200\n",
      "25709/25709 [==============================] - 13s 493us/step - loss: 1.1771 - acc: 0.6276 - val_loss: 1.3901 - val_acc: 0.5433\n",
      "Epoch 159/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.1692 - acc: 0.6280 - val_loss: 1.3896 - val_acc: 0.5457\n",
      "Epoch 160/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.1674 - acc: 0.6296 - val_loss: 1.3870 - val_acc: 0.5470\n",
      "Epoch 161/200\n",
      "25709/25709 [==============================] - 13s 491us/step - loss: 1.1647 - acc: 0.6268 - val_loss: 1.3874 - val_acc: 0.5450\n",
      "Epoch 162/200\n",
      "25709/25709 [==============================] - 13s 498us/step - loss: 1.1652 - acc: 0.6301 - val_loss: 1.3870 - val_acc: 0.5493\n",
      "Epoch 163/200\n",
      "25709/25709 [==============================] - 13s 497us/step - loss: 1.1605 - acc: 0.6288 - val_loss: 1.3850 - val_acc: 0.5453\n",
      "Epoch 164/200\n",
      "25709/25709 [==============================] - 13s 496us/step - loss: 1.1556 - acc: 0.6330 - val_loss: 1.3852 - val_acc: 0.5450\n",
      "Epoch 165/200\n",
      "25709/25709 [==============================] - 13s 491us/step - loss: 1.1537 - acc: 0.6332 - val_loss: 1.3863 - val_acc: 0.5483\n",
      "Epoch 166/200\n",
      "25709/25709 [==============================] - 12s 485us/step - loss: 1.1596 - acc: 0.6317 - val_loss: 1.3856 - val_acc: 0.5473\n",
      "Epoch 167/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.1463 - acc: 0.6389 - val_loss: 1.3809 - val_acc: 0.5483\n",
      "Epoch 168/200\n",
      "25709/25709 [==============================] - 13s 489us/step - loss: 1.1466 - acc: 0.6336 - val_loss: 1.3801 - val_acc: 0.5450\n",
      "Epoch 169/200\n",
      "25709/25709 [==============================] - 13s 495us/step - loss: 1.1390 - acc: 0.6379 - val_loss: 1.3830 - val_acc: 0.5477\n",
      "Epoch 170/200\n",
      "25709/25709 [==============================] - 13s 498us/step - loss: 1.1389 - acc: 0.6386 - val_loss: 1.3794 - val_acc: 0.5477\n",
      "Epoch 171/200\n",
      "25709/25709 [==============================] - 13s 494us/step - loss: 1.1336 - acc: 0.6427 - val_loss: 1.3789 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "25709/25709 [==============================] - 13s 492us/step - loss: 1.1333 - acc: 0.6394 - val_loss: 1.3802 - val_acc: 0.5467\n",
      "Epoch 173/200\n",
      "25709/25709 [==============================] - 13s 491us/step - loss: 1.1305 - acc: 0.6423 - val_loss: 1.3792 - val_acc: 0.5480\n",
      "Epoch 174/200\n",
      "25709/25709 [==============================] - 12s 472us/step - loss: 1.1277 - acc: 0.6409 - val_loss: 1.3800 - val_acc: 0.5467\n",
      "Epoch 175/200\n",
      "25709/25709 [==============================] - 12s 459us/step - loss: 1.1270 - acc: 0.6425 - val_loss: 1.3755 - val_acc: 0.5487\n",
      "Epoch 176/200\n",
      "25709/25709 [==============================] - 12s 458us/step - loss: 1.1218 - acc: 0.6453 - val_loss: 1.3780 - val_acc: 0.5433\n",
      "Epoch 177/200\n",
      "25709/25709 [==============================] - 12s 470us/step - loss: 1.1286 - acc: 0.6431 - val_loss: 1.3737 - val_acc: 0.5480\n",
      "Epoch 178/200\n",
      "25709/25709 [==============================] - 12s 473us/step - loss: 1.1170 - acc: 0.6439 - val_loss: 1.3758 - val_acc: 0.5477\n",
      "Epoch 179/200\n",
      "25709/25709 [==============================] - 12s 482us/step - loss: 1.1184 - acc: 0.6436 - val_loss: 1.3779 - val_acc: 0.5507\n",
      "Epoch 180/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.1101 - acc: 0.6437 - val_loss: 1.3754 - val_acc: 0.5487\n",
      "Epoch 181/200\n",
      "25709/25709 [==============================] - 12s 478us/step - loss: 1.1162 - acc: 0.6428 - val_loss: 1.3739 - val_acc: 0.5480\n",
      "Epoch 182/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.1155 - acc: 0.6432 - val_loss: 1.3732 - val_acc: 0.5497\n",
      "Epoch 183/200\n",
      "25709/25709 [==============================] - 12s 485us/step - loss: 1.1133 - acc: 0.6444 - val_loss: 1.3745 - val_acc: 0.5473\n",
      "Epoch 184/200\n",
      "25709/25709 [==============================] - 12s 484us/step - loss: 1.1088 - acc: 0.6505 - val_loss: 1.3719 - val_acc: 0.5447\n",
      "Epoch 185/200\n",
      "25709/25709 [==============================] - 12s 476us/step - loss: 1.1027 - acc: 0.6491 - val_loss: 1.3729 - val_acc: 0.5450\n",
      "Epoch 186/200\n",
      "25709/25709 [==============================] - 12s 470us/step - loss: 1.0987 - acc: 0.6502 - val_loss: 1.3712 - val_acc: 0.5473\n",
      "Epoch 187/200\n",
      "25709/25709 [==============================] - 12s 476us/step - loss: 1.0949 - acc: 0.6558 - val_loss: 1.3761 - val_acc: 0.5463\n",
      "Epoch 188/200\n",
      "25709/25709 [==============================] - 12s 476us/step - loss: 1.1007 - acc: 0.6482 - val_loss: 1.3722 - val_acc: 0.5497\n",
      "Epoch 189/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.0951 - acc: 0.6511 - val_loss: 1.3677 - val_acc: 0.5483\n",
      "Epoch 190/200\n",
      "25709/25709 [==============================] - 12s 478us/step - loss: 1.0942 - acc: 0.6525 - val_loss: 1.3692 - val_acc: 0.5470\n",
      "Epoch 191/200\n",
      "25709/25709 [==============================] - 12s 473us/step - loss: 1.0906 - acc: 0.6528 - val_loss: 1.3685 - val_acc: 0.5477\n",
      "Epoch 192/200\n",
      "25709/25709 [==============================] - 12s 470us/step - loss: 1.0927 - acc: 0.6536 - val_loss: 1.3698 - val_acc: 0.5500\n",
      "Epoch 193/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.0868 - acc: 0.6529 - val_loss: 1.3668 - val_acc: 0.5503\n",
      "Epoch 194/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.0806 - acc: 0.6565 - val_loss: 1.3641 - val_acc: 0.5507\n",
      "Epoch 195/200\n",
      "25709/25709 [==============================] - 12s 477us/step - loss: 1.0896 - acc: 0.6545 - val_loss: 1.3668 - val_acc: 0.5483\n",
      "Epoch 196/200\n",
      "25709/25709 [==============================] - 13s 499us/step - loss: 1.0821 - acc: 0.6602 - val_loss: 1.3697 - val_acc: 0.5500\n",
      "Epoch 197/200\n",
      "25709/25709 [==============================] - 13s 490us/step - loss: 1.0800 - acc: 0.6578 - val_loss: 1.3649 - val_acc: 0.5500\n",
      "Epoch 198/200\n",
      "25709/25709 [==============================] - 12s 480us/step - loss: 1.0716 - acc: 0.6632 - val_loss: 1.3663 - val_acc: 0.5497\n",
      "Epoch 199/200\n",
      "25709/25709 [==============================] - 12s 460us/step - loss: 1.0684 - acc: 0.6608 - val_loss: 1.3699 - val_acc: 0.5477\n",
      "Epoch 200/200\n",
      "25709/25709 [==============================] - 12s 460us/step - loss: 1.0704 - acc: 0.6600 - val_loss: 1.3692 - val_acc: 0.5497\n"
     ]
    }
   ],
   "source": [
    "rate = 1e-5\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=rate, decay=1e-6)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "print('Learning rate: %f' % rate)\n",
    "loss = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=200,\n",
    "              validation_data=(X_val, y_val),\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "score = model.evaluate(X_pri_test, y_pri_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05\n",
      "Test loss: 1.3512535285949707\n",
      "Test accuracy: 0.547\n"
     ]
    }
   ],
   "source": [
    "print('Learning rate:', rate)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('cross_entropy loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"acc\"],'r-x', label=\"Train Accuracy\")\n",
    "    ax.plot(history.history[\"val_acc\"],'b-x', label=\"Validation Accuracy\")\n",
    "    ax.legend()\n",
    "    ax.set_title('accuracy')\n",
    "    ax.grid(True)\n",
    "    \n",
    "\n",
    "plot_loss_accuracy(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1505pt\" viewBox=\"0.00 0.00 228.00 1505.00\" width=\"228pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1501)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-1501 224,-1501 224,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 476300568 -->\n",
       "<g class=\"node\" id=\"node1\"><title>476300568</title>\n",
       "<polygon fill=\"none\" points=\"47,-1460.5 47,-1496.5 173,-1496.5 173,-1460.5 47,-1460.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-1474.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 476300680 -->\n",
       "<g class=\"node\" id=\"node2\"><title>476300680</title>\n",
       "<polygon fill=\"none\" points=\"1.5,-1387.5 1.5,-1423.5 218.5,-1423.5 218.5,-1387.5 1.5,-1387.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-1401.8\">zero_padding2d_1: ZeroPadding2D</text>\n",
       "</g>\n",
       "<!-- 476300568&#45;&gt;476300680 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>476300568-&gt;476300680</title>\n",
       "<path d=\"M110,-1460.31C110,-1452.29 110,-1442.55 110,-1433.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-1433.53 110,-1423.53 106.5,-1433.53 113.5,-1433.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 81397464 -->\n",
       "<g class=\"node\" id=\"node3\"><title>81397464</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-1314.5 57.5,-1350.5 162.5,-1350.5 162.5,-1314.5 57.5,-1314.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-1328.8\">conv1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 476300680&#45;&gt;81397464 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>476300680-&gt;81397464</title>\n",
       "<path d=\"M110,-1387.31C110,-1379.29 110,-1369.55 110,-1360.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-1360.53 110,-1350.53 106.5,-1360.53 113.5,-1360.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 476302472 -->\n",
       "<g class=\"node\" id=\"node4\"><title>476302472</title>\n",
       "<polygon fill=\"none\" points=\"15.5,-1241.5 15.5,-1277.5 204.5,-1277.5 204.5,-1241.5 15.5,-1241.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-1255.8\">bn_conv1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 81397464&#45;&gt;476302472 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>81397464-&gt;476302472</title>\n",
       "<path d=\"M110,-1314.31C110,-1306.29 110,-1296.55 110,-1287.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-1287.53 110,-1277.53 106.5,-1287.53 113.5,-1287.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 476301240 -->\n",
       "<g class=\"node\" id=\"node5\"><title>476301240</title>\n",
       "<polygon fill=\"none\" points=\"36,-1168.5 36,-1204.5 184,-1204.5 184,-1168.5 36,-1168.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-1182.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 476302472&#45;&gt;476301240 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>476302472-&gt;476301240</title>\n",
       "<path d=\"M110,-1241.31C110,-1233.29 110,-1223.55 110,-1214.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-1214.53 110,-1204.53 106.5,-1214.53 113.5,-1214.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 307038080 -->\n",
       "<g class=\"node\" id=\"node6\"><title>307038080</title>\n",
       "<polygon fill=\"none\" points=\"5.5,-1095.5 5.5,-1131.5 214.5,-1131.5 214.5,-1095.5 5.5,-1095.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-1109.8\">max_pooling2d_1: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 476301240&#45;&gt;307038080 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>476301240-&gt;307038080</title>\n",
       "<path d=\"M110,-1168.31C110,-1160.29 110,-1150.55 110,-1141.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-1141.53 110,-1131.53 106.5,-1141.53 113.5,-1141.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 307598840 -->\n",
       "<g class=\"node\" id=\"node7\"><title>307598840</title>\n",
       "<polygon fill=\"none\" points=\"31,-1022.5 31,-1058.5 189,-1058.5 189,-1022.5 31,-1022.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-1036.8\">res2a_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 307038080&#45;&gt;307598840 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>307038080-&gt;307598840</title>\n",
       "<path d=\"M110,-1095.31C110,-1087.29 110,-1077.55 110,-1068.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-1068.53 110,-1058.53 106.5,-1068.53 113.5,-1068.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 317274040 -->\n",
       "<g class=\"node\" id=\"node8\"><title>317274040</title>\n",
       "<polygon fill=\"none\" points=\"1,-949.5 1,-985.5 219,-985.5 219,-949.5 1,-949.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-963.8\">bn2a_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 307598840&#45;&gt;317274040 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>307598840-&gt;317274040</title>\n",
       "<path d=\"M110,-1022.31C110,-1014.29 110,-1004.55 110,-995.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-995.529 110,-985.529 106.5,-995.529 113.5,-995.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 323840712 -->\n",
       "<g class=\"node\" id=\"node9\"><title>323840712</title>\n",
       "<polygon fill=\"none\" points=\"36,-876.5 36,-912.5 184,-912.5 184,-876.5 36,-876.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-890.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 317274040&#45;&gt;323840712 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>317274040-&gt;323840712</title>\n",
       "<path d=\"M110,-949.313C110,-941.289 110,-931.547 110,-922.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-922.529 110,-912.529 106.5,-922.529 113.5,-922.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 326610392 -->\n",
       "<g class=\"node\" id=\"node10\"><title>326610392</title>\n",
       "<polygon fill=\"none\" points=\"30,-803.5 30,-839.5 190,-839.5 190,-803.5 30,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-817.8\">res2a_branch2b: Conv2D</text>\n",
       "</g>\n",
       "<!-- 323840712&#45;&gt;326610392 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>323840712-&gt;326610392</title>\n",
       "<path d=\"M110,-876.313C110,-868.289 110,-858.547 110,-849.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-849.529 110,-839.529 106.5,-849.529 113.5,-849.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 173779152 -->\n",
       "<g class=\"node\" id=\"node11\"><title>173779152</title>\n",
       "<polygon fill=\"none\" points=\"0,-730.5 0,-766.5 220,-766.5 220,-730.5 0,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-744.8\">bn2a_branch2b: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 326610392&#45;&gt;173779152 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>326610392-&gt;173779152</title>\n",
       "<path d=\"M110,-803.313C110,-795.289 110,-785.547 110,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-776.529 110,-766.529 106.5,-776.529 113.5,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 366800064 -->\n",
       "<g class=\"node\" id=\"node12\"><title>366800064</title>\n",
       "<polygon fill=\"none\" points=\"36,-657.5 36,-693.5 184,-693.5 184,-657.5 36,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-671.8\">activation_3: Activation</text>\n",
       "</g>\n",
       "<!-- 173779152&#45;&gt;366800064 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>173779152-&gt;366800064</title>\n",
       "<path d=\"M110,-730.313C110,-722.289 110,-712.547 110,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-703.529 110,-693.529 106.5,-703.529 113.5,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 367447064 -->\n",
       "<g class=\"node\" id=\"node13\"><title>367447064</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-584.5 30.5,-620.5 189.5,-620.5 189.5,-584.5 30.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-598.8\">res2a_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 366800064&#45;&gt;367447064 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>366800064-&gt;367447064</title>\n",
       "<path d=\"M110,-657.313C110,-649.289 110,-639.547 110,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-630.529 110,-620.529 106.5,-630.529 113.5,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 489760360 -->\n",
       "<g class=\"node\" id=\"node14\"><title>489760360</title>\n",
       "<polygon fill=\"none\" points=\"0.5,-511.5 0.5,-547.5 219.5,-547.5 219.5,-511.5 0.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-525.8\">bn2a_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 367447064&#45;&gt;489760360 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>367447064-&gt;489760360</title>\n",
       "<path d=\"M110,-584.313C110,-576.289 110,-566.547 110,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-557.529 110,-547.529 106.5,-557.529 113.5,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 798014768 -->\n",
       "<g class=\"node\" id=\"node15\"><title>798014768</title>\n",
       "<polygon fill=\"none\" points=\"34,-438.5 34,-474.5 186,-474.5 186,-438.5 34,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-452.8\">res2a_branch1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 489760360&#45;&gt;798014768 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>489760360-&gt;798014768</title>\n",
       "<path d=\"M110,-511.313C110,-503.289 110,-493.547 110,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-484.529 110,-474.529 106.5,-484.529 113.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 798013256 -->\n",
       "<g class=\"node\" id=\"node16\"><title>798013256</title>\n",
       "<polygon fill=\"none\" points=\"4,-365.5 4,-401.5 216,-401.5 216,-365.5 4,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-379.8\">bn2a_branch1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 798014768&#45;&gt;798013256 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>798014768-&gt;798013256</title>\n",
       "<path d=\"M110,-438.313C110,-430.289 110,-420.547 110,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-411.529 110,-401.529 106.5,-411.529 113.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 829657888 -->\n",
       "<g class=\"node\" id=\"node17\"><title>829657888</title>\n",
       "<polygon fill=\"none\" points=\"19.5,-292.5 19.5,-328.5 200.5,-328.5 200.5,-292.5 19.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-306.8\">avg_pool: AveragePooling2D</text>\n",
       "</g>\n",
       "<!-- 798013256&#45;&gt;829657888 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>798013256-&gt;829657888</title>\n",
       "<path d=\"M110,-365.313C110,-357.289 110,-347.547 110,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-338.529 110,-328.529 106.5,-338.529 113.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 833506944 -->\n",
       "<g class=\"node\" id=\"node18\"><title>833506944</title>\n",
       "<polygon fill=\"none\" points=\"55.5,-219.5 55.5,-255.5 164.5,-255.5 164.5,-219.5 55.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-233.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 829657888&#45;&gt;833506944 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>829657888-&gt;833506944</title>\n",
       "<path d=\"M110,-292.313C110,-284.289 110,-274.547 110,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-265.529 110,-255.529 106.5,-265.529 113.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 833628144 -->\n",
       "<g class=\"node\" id=\"node19\"><title>833628144</title>\n",
       "<polygon fill=\"none\" points=\"58,-146.5 58,-182.5 162,-182.5 162,-146.5 58,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-160.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 833506944&#45;&gt;833628144 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>833506944-&gt;833628144</title>\n",
       "<path d=\"M110,-219.313C110,-211.289 110,-201.547 110,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-192.529 110,-182.529 106.5,-192.529 113.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 834241480 -->\n",
       "<g class=\"node\" id=\"node20\"><title>834241480</title>\n",
       "<polygon fill=\"none\" points=\"45,-73.5 45,-109.5 175,-109.5 175,-73.5 45,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-87.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 833628144&#45;&gt;834241480 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>833628144-&gt;834241480</title>\n",
       "<path d=\"M110,-146.313C110,-138.289 110,-128.547 110,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-119.529 110,-109.529 106.5,-119.529 113.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 834608320 -->\n",
       "<g class=\"node\" id=\"node21\"><title>834608320</title>\n",
       "<polygon fill=\"none\" points=\"72,-0.5 72,-36.5 148,-36.5 148,-0.5 72,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-14.8\">fc7: Dense</text>\n",
       "</g>\n",
       "<!-- 834241480&#45;&gt;834608320 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>834241480-&gt;834608320</title>\n",
       "<path d=\"M110,-73.3129C110,-65.2895 110,-55.5475 110,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113.5,-46.5288 110,-36.5288 106.5,-46.5289 113.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "input_1:0 is both fed and fetched.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b45830d244dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mactivation_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Creates a model that will return these outputs, given the model input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Returns a list of five Numpy arrays: one array per layer activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted class is:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2671\u001b[1;33m                                 session)\n\u001b[0m\u001b[0;32m   2672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2622\u001b[0m         \u001b[1;31m# Create callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2623\u001b[1;33m         \u001b[0mcallable_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2624\u001b[0m         \u001b[1;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2625\u001b[0m         \u001b[1;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     \"\"\"\n\u001b[0;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session, callable_options)\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[1;32m-> 1425\u001b[1;33m               session._session, options_ptr, status)\n\u001b[0m\u001b[0;32m   1426\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cecs551-project-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: input_1:0 is both fed and fetched."
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers[:12]] # Extracts the outputs of the top 12 layers\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input\n",
    "img_tensor = np.expand_dims(X_val[0], axis=0)\n",
    "activations = activation_model.predict(img_tensor) # Returns a list of five Numpy arrays: one array per layer activation\n",
    "classes = model.predict_classes(img_tensor, batch_size=1)\n",
    "print(\"Predicted class is:\",classes)\n",
    "layer_names = []\n",
    "for layer in model.layers[:12]:\n",
    "    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
    "    \n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
    "    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, # Displays the grid\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
