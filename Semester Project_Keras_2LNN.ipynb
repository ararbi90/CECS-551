{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a CNN to classify images in the CIFAR-10 Dataset\n",
    "We will work with the CIFAR-10 Dataset. This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The 10 classes are:\n",
    "\n",
    "airplane\n",
    "automobile\n",
    "bird\n",
    "cat\n",
    "deer\n",
    "dog\n",
    "frog\n",
    "horse\n",
    "ship\n",
    "truck\n",
    "For details about CIFAR-10 see: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "For a compilation of published performance results on CIFAR 10, see: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "Building Convolutional Neural Nets\n",
    "In this exercise we will build and train our first convolutional neural networks. In the first part, we walk through the different layers and how they are configured. In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Convolutional Neural Nets \n",
    "In this exercise we will build and train our first convolutional neural networks. In the first part, we walk through the different layers and how they are configured. In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear previously loaded data.\n",
      "Train data shape:  (25709, 48, 48, 1)\n",
      "Train labels shape:  (25709,)\n",
      "Validation data shape:  (3000, 48, 48, 1)\n",
      "Validation labels shape:  (3000,)\n",
      "Public test data shape:  (1000, 48, 48, 1)\n",
      "Public test labels shape:  (1000,)\n",
      "Private test data shape:  (1000, 48, 48, 1)\n",
      "Private test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data\n",
    "\n",
    "def get_data(num_training=25709, num_validation=3000, num_pub_test=1000, num_pri_test=1000):\n",
    "    \"\"\"\n",
    "    Load the dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = load_data()\n",
    "        \n",
    "#     # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_pub_test))\n",
    "    X_pub_test = X_pub_test[mask]\n",
    "    y_pub_test = y_pub_test[mask]\n",
    "    mask = list(range(num_pri_test))\n",
    "    X_pri_test = X_pri_test[mask]\n",
    "    y_pri_test = y_pri_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_pub_test -= mean_image\n",
    "    X_pri_test -= mean_image\n",
    "#     X_train /= np.std(X_train, axis = 0)\n",
    "#     X_val /= np.std(X_val, axis = 0)\n",
    "#     X_pub_test /= np.std(X_pub_test, axis = 0)\n",
    "#     X_pri_test /= np.std(X_pri_test, axis = 0)\n",
    "\n",
    "    # Reshape data to rows\n",
    "#     X_train = X_train.reshape(num_training, -1)\n",
    "#     X_val = X_val.reshape(num_validation, -1)\n",
    "#     X_pub_test = X_pub_test.reshape(num_pub_test, -1)\n",
    "#     X_pri_test = X_pri_test.reshape(num_pri_test, -1)\n",
    "    return X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "    #return X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_pub_test, y_pub_test\n",
    "   del X_pri_test, y_pri_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "#X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Public test data shape: ', X_pub_test.shape)\n",
    "print('Public test labels shape: ', y_pub_test.shape)\n",
    "print('Private test data shape: ', X_pri_test.shape)\n",
    "print('Private test labels shape: ', y_pri_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25709, 48, 48, 1)\n",
      "25709 train samples\n",
      "3000 val samples\n",
      "1000 test samples\n",
      "1000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'val samples')\n",
    "print(X_pub_test.shape[0], 'test samples')\n",
    "print(X_pri_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n",
      "[[[116.89206115]\n",
      "  [119.91773309]\n",
      "  [113.94534988]\n",
      "  ...\n",
      "  [-90.0524719 ]\n",
      "  [-90.98269089]\n",
      "  [-90.89462834]]\n",
      "\n",
      " [[119.02932825]\n",
      "  [117.19362869]\n",
      "  [114.08168346]\n",
      "  ...\n",
      "  [-82.99704384]\n",
      "  [-81.02816134]\n",
      "  [-80.93655918]]\n",
      "\n",
      " [[120.34672683]\n",
      "  [116.38850208]\n",
      "  [115.17161305]\n",
      "  ...\n",
      "  [-71.96172547]\n",
      "  [-72.92076705]\n",
      "  [-71.91115952]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -0.24314442]\n",
      "  [-98.27519546]\n",
      "  [-76.40091019]\n",
      "  ...\n",
      "  [-16.53942199]\n",
      "  [-70.36668093]\n",
      "  [-85.17631958]]\n",
      "\n",
      " [[ -0.23151426]\n",
      "  [-94.2996616 ]\n",
      "  [-79.33743047]\n",
      "  ...\n",
      "  [-21.54564549]\n",
      "  [-75.32218289]\n",
      "  [-87.19125598]]\n",
      "\n",
      " [[ -2.23104749]\n",
      "  [-91.24275546]\n",
      "  [-81.06134039]\n",
      "  ...\n",
      "  [-30.46228947]\n",
      "  [-73.21521646]\n",
      "  [-89.01435295]]]\n"
     ]
    }
   ],
   "source": [
    "## Each image is a 32 x 32 x 3 numpy array\n",
    "print(X_train[444].shape)\n",
    "print(X_train[444])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[444])\n",
    "plt.imshow(X_train[444].reshape(48, 48), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25709, 48, 48, 1) train samples\n",
      "(1000, 48, 48, 1) public test samples\n",
      "(1000, 48, 48, 1) private test sample\n"
     ]
    }
   ],
   "source": [
    "# this is the shape of the np.array x_train\n",
    "# it is 3 dimensional.\n",
    "print(X_train.shape, 'train samples')\n",
    "print(X_pub_test.shape, 'public test samples')\n",
    "print(X_pri_test.shape, 'private test sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For our purposes, these images are just a vector of 784 inputs, so let's convert\n",
    "X_train = X_train.reshape(len(X_train), 48*48)\n",
    "X_val = X_val.reshape(len(X_val), 48*48)\n",
    "X_pub_test = X_pub_test.reshape(len(X_pub_test), 48*48)\n",
    "X_pri_test = X_pri_test.reshape(len(X_pri_test), 48*48)\n",
    "\n",
    "\n",
    "# As before, let's make everything float and scale\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_pub_test = X_pub_test.astype('float32')\n",
    "X_pri_test = X_pri_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_pub_test /= 255\n",
    "X_pri_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 7\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_pub_test = keras.utils.to_categorical(y_pub_test, num_classes)\n",
    "\n",
    "y_pri_test = keras.utils.to_categorical(y_pri_test, num_classes)\n",
    "\n",
    "y_train[333]  # now the digit k is represented by a 1 in the kth entry (0-indexed) of the length 10 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 150)               345750    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 1057      \n",
      "=================================================================\n",
      "Total params: 346,807\n",
      "Trainable params: 346,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ### Build your model here\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(150, activation='relu', input_shape=(2304,)))\n",
    "model_2.add(Dropout(0.4))\n",
    "model_2.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compile the model\n",
    "learning_rate = 0.0005\n",
    "#learning_rate = 0.003035522\n",
    "opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "sgd = keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam =keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "# note that `categorical cross entropy` is the natural generalization \n",
    "# of the loss function we had in binary classification case, to multi class case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25709 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "25709/25709 [==============================] - 3s 126us/step - loss: 1.7616 - acc: 0.3170 - val_loss: 1.6104 - val_acc: 0.3673\n",
      "Epoch 2/100\n",
      "25709/25709 [==============================] - 3s 97us/step - loss: 1.6280 - acc: 0.3654 - val_loss: 1.5847 - val_acc: 0.3787\n",
      "Epoch 3/100\n",
      "25709/25709 [==============================] - 3s 99us/step - loss: 1.5767 - acc: 0.3882 - val_loss: 1.5542 - val_acc: 0.3923\n",
      "Epoch 4/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.5502 - acc: 0.3959 - val_loss: 1.5421 - val_acc: 0.4023\n",
      "Epoch 5/100\n",
      "25709/25709 [==============================] - 2s 81us/step - loss: 1.5307 - acc: 0.4048 - val_loss: 1.5453 - val_acc: 0.3977\n",
      "Epoch 6/100\n",
      "25709/25709 [==============================] - 2s 79us/step - loss: 1.5147 - acc: 0.4163 - val_loss: 1.5216 - val_acc: 0.4120\n",
      "Epoch 7/100\n",
      "25709/25709 [==============================] - 2s 75us/step - loss: 1.4923 - acc: 0.4231 - val_loss: 1.5275 - val_acc: 0.4083\n",
      "Epoch 8/100\n",
      "25709/25709 [==============================] - 2s 75us/step - loss: 1.4758 - acc: 0.4258 - val_loss: 1.5210 - val_acc: 0.4167\n",
      "Epoch 9/100\n",
      "25709/25709 [==============================] - 2s 76us/step - loss: 1.4676 - acc: 0.4358 - val_loss: 1.5163 - val_acc: 0.4120\n",
      "Epoch 10/100\n",
      "25709/25709 [==============================] - 2s 77us/step - loss: 1.4509 - acc: 0.4443 - val_loss: 1.4907 - val_acc: 0.4277\n",
      "Epoch 11/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.4299 - acc: 0.4537 - val_loss: 1.5055 - val_acc: 0.4220\n",
      "Epoch 12/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.4173 - acc: 0.4613 - val_loss: 1.5050 - val_acc: 0.4200\n",
      "Epoch 13/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.4040 - acc: 0.4597 - val_loss: 1.5011 - val_acc: 0.4233\n",
      "Epoch 14/100\n",
      "25709/25709 [==============================] - 2s 79us/step - loss: 1.3861 - acc: 0.4661 - val_loss: 1.5035 - val_acc: 0.4180\n",
      "Epoch 15/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.3751 - acc: 0.4792 - val_loss: 1.5128 - val_acc: 0.4243\n",
      "Epoch 16/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.3609 - acc: 0.4841 - val_loss: 1.4982 - val_acc: 0.4273\n",
      "Epoch 17/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.3438 - acc: 0.4906 - val_loss: 1.4906 - val_acc: 0.4337\n",
      "Epoch 18/100\n",
      "25709/25709 [==============================] - 2s 81us/step - loss: 1.3224 - acc: 0.4970 - val_loss: 1.4960 - val_acc: 0.4290\n",
      "Epoch 19/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.3178 - acc: 0.4984 - val_loss: 1.4978 - val_acc: 0.4360\n",
      "Epoch 20/100\n",
      "25709/25709 [==============================] - 2s 78us/step - loss: 1.2989 - acc: 0.5049 - val_loss: 1.5097 - val_acc: 0.4250\n",
      "Epoch 21/100\n",
      "25709/25709 [==============================] - 2s 79us/step - loss: 1.2927 - acc: 0.5091 - val_loss: 1.5051 - val_acc: 0.4397\n",
      "Epoch 22/100\n",
      "25709/25709 [==============================] - 2s 79us/step - loss: 1.2735 - acc: 0.5176 - val_loss: 1.5155 - val_acc: 0.4260\n",
      "Epoch 23/100\n",
      "25709/25709 [==============================] - 2s 80us/step - loss: 1.2596 - acc: 0.5225 - val_loss: 1.5146 - val_acc: 0.4307\n",
      "Epoch 24/100\n",
      "  768/25709 [..............................] - ETA: 1s - loss: 1.2828 - acc: 0.5182"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-32c5bda0a135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     validation_data=(X_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myproj/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/myproj/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myproj/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myproj/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myproj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# And now let's fit.\n",
    "\n",
    "batch_size = 64  # mini-batch with 128 examples\n",
    "epochs = 100\n",
    "history = model_2.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will use Keras evaluate function to evaluate performance on the test set\n",
    "\n",
    "score = model_2.evaluate(X_pri_test, y_pri_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('cross_entropy loss')\n",
    "    \n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"acc\"],'r-x', label=\"Train Accuracy\")\n",
    "    ax.plot(history.history[\"val_acc\"],'b-x', label=\"Validation Accuracy\")\n",
    "    ax.legend()\n",
    "    ax.set_title('accuracy')\n",
    "    ax.grid(True)\n",
    "    \n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
