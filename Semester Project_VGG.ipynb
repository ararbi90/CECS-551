{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (25709, 48, 48, 1)\n",
      "Train labels shape:  (25709,)\n",
      "Validation data shape:  (3000, 48, 48, 1)\n",
      "Validation labels shape:  (3000,)\n",
      "Public test data shape:  (1000, 48, 48, 1)\n",
      "Public test labels shape:  (1000,)\n",
      "Private test data shape:  (1000, 48, 48, 1)\n",
      "Private test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data\n",
    "\n",
    "def get_data(num_training=25709, num_validation=3000, num_pub_test=1000, num_pri_test=1000):\n",
    "    \"\"\"\n",
    "    Load the dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = load_data()\n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_pub_test))\n",
    "    X_pub_test = X_pub_test[mask]\n",
    "    y_pub_test = y_pub_test[mask]\n",
    "    mask = list(range(num_pri_test))\n",
    "    X_pri_test = X_pri_test[mask]\n",
    "    y_pri_test = y_pri_test[mask]\n",
    "\n",
    "#     # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_pub_test -= mean_image\n",
    "    X_pri_test -= mean_image  \n",
    "    return X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "    #return X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_pub_test, y_pub_test\n",
    "   del X_pri_test, y_pri_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "#X_train, y_train, X_pub_test, y_pub_test, X_pri_test, y_pri_test = get_data()\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Public test data shape: ', X_pub_test.shape)\n",
    "print('Public test labels shape: ', y_pub_test.shape)\n",
    "print('Private test data shape: ', X_pri_test.shape)\n",
    "print('Private test labels shape: ', y_pri_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[444].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[444])\n",
    "plt.imshow(X_train[444].reshape(48, 48));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_pub_test = keras.utils.to_categorical(y_pub_test, num_classes)\n",
    "y_pri_test = keras.utils.to_categorical(y_pri_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, let's make everything float and scale\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_pub_test = X_pub_test.astype('float32')\n",
    "X_pri_test = X_pri_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_pub_test /= 255\n",
    "X_pri_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 48, 48, 16)        80        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 8, 8, 64)          16448     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 3591      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 562,263\n",
      "Trainable params: 560,823\n",
      "Non-trainable params: 1,440\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48, 48, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VGG MODEL\n",
    "# Create model_2 as mentioned in the exercise\n",
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (2, 2), padding=\"same\",\n",
    "input_shape=X_train.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(32, (2, 2), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (2, 2), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(64, (2, 2), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (2, 2), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# first (and only) set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# softmax classifier\n",
    "model.add(Dense(7))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25709 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "25709/25709 [==============================] - 48s 2ms/step - loss: 2.1486 - acc: 0.2601 - val_loss: 1.6227 - val_acc: 0.3757\n",
      "Epoch 2/50\n",
      "25709/25709 [==============================] - 44s 2ms/step - loss: 1.6666 - acc: 0.3521 - val_loss: 1.5034 - val_acc: 0.4117\n",
      "Epoch 3/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.5503 - acc: 0.3971 - val_loss: 1.3804 - val_acc: 0.4650\n",
      "Epoch 4/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.4803 - acc: 0.4289 - val_loss: 1.3641 - val_acc: 0.4733\n",
      "Epoch 5/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.4319 - acc: 0.4482 - val_loss: 1.3269 - val_acc: 0.4870\n",
      "Epoch 6/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.3903 - acc: 0.4655 - val_loss: 1.2931 - val_acc: 0.4993\n",
      "Epoch 7/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.3597 - acc: 0.4800 - val_loss: 1.2495 - val_acc: 0.5237\n",
      "Epoch 8/50\n",
      "25709/25709 [==============================] - 40s 2ms/step - loss: 1.3386 - acc: 0.4879 - val_loss: 1.2457 - val_acc: 0.5200\n",
      "Epoch 9/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.3155 - acc: 0.4970 - val_loss: 1.2084 - val_acc: 0.5350\n",
      "Epoch 10/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.2891 - acc: 0.5083 - val_loss: 1.2112 - val_acc: 0.5283\n",
      "Epoch 11/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.2730 - acc: 0.5140 - val_loss: 1.2687 - val_acc: 0.5170\n",
      "Epoch 12/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.2569 - acc: 0.5202 - val_loss: 1.1523 - val_acc: 0.5643\n",
      "Epoch 13/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.2443 - acc: 0.5270 - val_loss: 1.1905 - val_acc: 0.5433\n",
      "Epoch 14/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.2264 - acc: 0.5323 - val_loss: 1.1347 - val_acc: 0.5623\n",
      "Epoch 15/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.2124 - acc: 0.5366 - val_loss: 1.1462 - val_acc: 0.5653\n",
      "Epoch 16/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1918 - acc: 0.5476 - val_loss: 1.1307 - val_acc: 0.5687\n",
      "Epoch 17/50\n",
      "25709/25709 [==============================] - 44s 2ms/step - loss: 1.1732 - acc: 0.5544 - val_loss: 1.1123 - val_acc: 0.5810\n",
      "Epoch 18/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1724 - acc: 0.5561 - val_loss: 1.1153 - val_acc: 0.5690\n",
      "Epoch 19/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1602 - acc: 0.5582 - val_loss: 1.3296 - val_acc: 0.4933\n",
      "Epoch 20/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1450 - acc: 0.5623 - val_loss: 1.0898 - val_acc: 0.5747\n",
      "Epoch 21/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1387 - acc: 0.5674 - val_loss: 1.0929 - val_acc: 0.5837\n",
      "Epoch 22/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1216 - acc: 0.5730 - val_loss: 1.1095 - val_acc: 0.5707\n",
      "Epoch 23/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1196 - acc: 0.5750 - val_loss: 1.1389 - val_acc: 0.5633\n",
      "Epoch 24/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.1028 - acc: 0.5838 - val_loss: 1.0991 - val_acc: 0.5790\n",
      "Epoch 25/50\n",
      "25709/25709 [==============================] - 43s 2ms/step - loss: 1.0937 - acc: 0.5878 - val_loss: 1.0868 - val_acc: 0.5883\n",
      "Epoch 26/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.0785 - acc: 0.5908 - val_loss: 1.0791 - val_acc: 0.5873\n",
      "Epoch 27/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.0743 - acc: 0.5938 - val_loss: 1.0799 - val_acc: 0.5920\n",
      "Epoch 28/50\n",
      "25709/25709 [==============================] - 38s 1ms/step - loss: 1.0572 - acc: 0.6043 - val_loss: 1.0933 - val_acc: 0.5757\n",
      "Epoch 29/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.0527 - acc: 0.6036 - val_loss: 1.1464 - val_acc: 0.5590\n",
      "Epoch 30/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.0386 - acc: 0.6071 - val_loss: 1.0708 - val_acc: 0.5930\n",
      "Epoch 31/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.0308 - acc: 0.6093 - val_loss: 1.0926 - val_acc: 0.5807\n",
      "Epoch 32/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.0200 - acc: 0.6179 - val_loss: 1.0743 - val_acc: 0.5903\n",
      "Epoch 33/50\n",
      "25709/25709 [==============================] - 40s 2ms/step - loss: 1.0131 - acc: 0.6195 - val_loss: 1.0656 - val_acc: 0.5893\n",
      "Epoch 34/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 1.0104 - acc: 0.6176 - val_loss: 1.0920 - val_acc: 0.5877\n",
      "Epoch 35/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9991 - acc: 0.6237 - val_loss: 1.0791 - val_acc: 0.5907\n",
      "Epoch 36/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9979 - acc: 0.6265 - val_loss: 1.0678 - val_acc: 0.5987\n",
      "Epoch 37/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9845 - acc: 0.6302 - val_loss: 1.0799 - val_acc: 0.5987\n",
      "Epoch 38/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9720 - acc: 0.6340 - val_loss: 1.0628 - val_acc: 0.6037\n",
      "Epoch 39/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9721 - acc: 0.6320 - val_loss: 1.0613 - val_acc: 0.6007\n",
      "Epoch 40/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9633 - acc: 0.6380 - val_loss: 1.0649 - val_acc: 0.5983\n",
      "Epoch 41/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9567 - acc: 0.6424 - val_loss: 1.0484 - val_acc: 0.6053\n",
      "Epoch 42/50\n",
      "25709/25709 [==============================] - 38s 1ms/step - loss: 0.9510 - acc: 0.6435 - val_loss: 1.0517 - val_acc: 0.6003\n",
      "Epoch 43/50\n",
      "25709/25709 [==============================] - 36s 1ms/step - loss: 0.9352 - acc: 0.6470 - val_loss: 1.0569 - val_acc: 0.6017\n",
      "Epoch 44/50\n",
      "25709/25709 [==============================] - 36s 1ms/step - loss: 0.9369 - acc: 0.6467 - val_loss: 1.0656 - val_acc: 0.5953\n",
      "Epoch 45/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9419 - acc: 0.6504 - val_loss: 1.0728 - val_acc: 0.6093\n",
      "Epoch 46/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9268 - acc: 0.6520 - val_loss: 1.0658 - val_acc: 0.6023\n",
      "Epoch 47/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9235 - acc: 0.6530 - val_loss: 1.0737 - val_acc: 0.5987\n",
      "Epoch 48/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9141 - acc: 0.6532 - val_loss: 1.0803 - val_acc: 0.6010\n",
      "Epoch 49/50\n",
      "25709/25709 [==============================] - 37s 1ms/step - loss: 0.9166 - acc: 0.6575 - val_loss: 1.0579 - val_acc: 0.6093\n",
      "Epoch 50/50\n",
      "25709/25709 [==============================] - 41s 2ms/step - loss: 0.9077 - acc: 0.6587 - val_loss: 1.0823 - val_acc: 0.5957\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam =Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=50,\n",
    "              validation_data=(X_val, y_val),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save trained model and history\n",
    "import pickle\n",
    "f = open('history.pckl', 'wb')\n",
    "pickle.dump(history.history, f)\n",
    "f.close()\n",
    "\n",
    "filename = 'Trained_VGG.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
